{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 nothing 0.04, X 0.04, Y 0.04, W 0.04, P 0.04, 12.7ms\n",
      "Speed: 10.5ms preprocess, 12.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.23, I 0.17, G 0.11, N 0.10, P 0.07, 12.8ms\n",
      "Speed: 6.5ms preprocess, 12.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.18, G 0.15, I 0.13, N 0.10, A 0.07, 10.7ms\n",
      "Speed: 5.9ms preprocess, 10.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.22, I 0.11, S 0.11, P 0.09, M 0.08, 11.4ms\n",
      "Speed: 4.9ms preprocess, 11.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.20, S 0.08, I 0.08, M 0.07, E 0.06, 9.8ms\n",
      "Speed: 6.4ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.20, S 0.09, M 0.08, E 0.07, I 0.06, 11.7ms\n",
      "Speed: 6.6ms preprocess, 11.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.20, G 0.16, P 0.12, I 0.12, N 0.11, 8.6ms\n",
      "Speed: 5.5ms preprocess, 8.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 I 0.22, G 0.19, P 0.16, S 0.11, X 0.08, 11.9ms\n",
      "Speed: 6.4ms preprocess, 11.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.16, G 0.14, I 0.13, P 0.13, N 0.08, 9.3ms\n",
      "Speed: 4.8ms preprocess, 9.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.17, G 0.14, I 0.11, N 0.11, P 0.10, 11.9ms\n",
      "Speed: 5.9ms preprocess, 11.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.20, P 0.13, M 0.12, I 0.09, N 0.07, 13.6ms\n",
      "Speed: 5.9ms preprocess, 13.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.15, I 0.11, G 0.11, P 0.10, N 0.09, 7.2ms\n",
      "Speed: 5.9ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.17, G 0.14, I 0.12, P 0.08, N 0.06, 6.1ms\n",
      "Speed: 4.5ms preprocess, 6.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.23, M 0.12, I 0.08, S 0.07, N 0.07, 9.4ms\n",
      "Speed: 6.0ms preprocess, 9.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.28, M 0.13, E 0.07, N 0.06, Q 0.06, 7.1ms\n",
      "Speed: 4.9ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.21, M 0.14, I 0.09, N 0.07, S 0.06, 8.0ms\n",
      "Speed: 4.5ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 N 0.66, M 0.31, S 0.01, G 0.01, T 0.00, 8.1ms\n",
      "Speed: 4.7ms preprocess, 8.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 Y 0.23, I 0.21, M 0.21, N 0.19, E 0.07, 6.4ms\n",
      "Speed: 4.5ms preprocess, 6.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 T 0.36, I 0.12, N 0.12, W 0.10, G 0.07, 7.0ms\n",
      "Speed: 4.8ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 0.96, K 0.02, V 0.01, U 0.01, F 0.00, 6.5ms\n",
      "Speed: 4.3ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 0.99, K 0.00, V 0.00, U 0.00, Y 0.00, 7.8ms\n",
      "Speed: 4.5ms preprocess, 7.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, V 0.00, D 0.00, I 0.00, 9.5ms\n",
      "Speed: 5.8ms preprocess, 9.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 7.2ms\n",
      "Speed: 5.8ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, A 0.00, 7.3ms\n",
      "Speed: 4.8ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, A 0.00, 7.7ms\n",
      "Speed: 5.1ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, K 0.00, 7.4ms\n",
      "Speed: 4.6ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, P 0.00, 6.0ms\n",
      "Speed: 4.6ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, A 0.00, 7.0ms\n",
      "Speed: 6.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, A 0.00, D 0.00, 6.0ms\n",
      "Speed: 5.2ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, I 0.00, 11.7ms\n",
      "Speed: 7.6ms preprocess, 11.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 6.5ms\n",
      "Speed: 4.8ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 7.3ms\n",
      "Speed: 4.3ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 6.2ms\n",
      "Speed: 5.0ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 8.2ms\n",
      "Speed: 5.2ms preprocess, 8.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 6.3ms\n",
      "Speed: 4.2ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 7.2ms\n",
      "Speed: 4.3ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 7.5ms\n",
      "Speed: 4.7ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 7.4ms\n",
      "Speed: 4.6ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 6.2ms\n",
      "Speed: 4.4ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 7.4ms\n",
      "Speed: 4.3ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, A 0.00, 6.9ms\n",
      "Speed: 4.4ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, G 0.00, D 0.00, I 0.00, 9.2ms\n",
      "Speed: 4.9ms preprocess, 9.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.55, Y 0.44, L 0.00, G 0.00, T 0.00, 7.7ms\n",
      "Speed: 5.1ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.75, M 0.08, N 0.05, E 0.04, T 0.02, 6.2ms\n",
      "Speed: 5.0ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.41, M 0.32, N 0.13, E 0.06, T 0.03, 6.8ms\n",
      "Speed: 5.0ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.40, M 0.32, N 0.14, E 0.04, T 0.03, 6.0ms\n",
      "Speed: 4.8ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.37, M 0.30, N 0.22, T 0.02, S 0.02, 6.3ms\n",
      "Speed: 4.5ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.36, A 0.31, N 0.21, T 0.03, E 0.03, 6.4ms\n",
      "Speed: 4.4ms preprocess, 6.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.39, N 0.32, A 0.15, E 0.04, T 0.03, 6.8ms\n",
      "Speed: 4.8ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 M 0.35, A 0.27, N 0.25, I 0.03, Y 0.03, 5.6ms\n",
      "Speed: 4.9ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.57, Y 0.15, G 0.09, N 0.08, M 0.05, 6.1ms\n",
      "Speed: 4.5ms preprocess, 6.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.99, T 0.00, Y 0.00, S 0.00, L 0.00, 5.9ms\n",
      "Speed: 4.4ms preprocess, 5.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, Y 0.00, I 0.00, L 0.00, 6.6ms\n",
      "Speed: 5.0ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, Y 0.00, G 0.00, L 0.00, 6.5ms\n",
      "Speed: 5.2ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, Y 0.00, G 0.00, L 0.00, 6.7ms\n",
      "Speed: 4.9ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, Y 0.00, T 0.00, G 0.00, L 0.00, 6.8ms\n",
      "Speed: 4.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, Y 0.00, T 0.00, L 0.00, G 0.00, 6.4ms\n",
      "Speed: 4.4ms preprocess, 6.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 0.98, G 0.01, Y 0.01, V 0.00, R 0.00, 5.7ms\n",
      "Speed: 4.4ms preprocess, 5.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, V 0.00, Y 0.00, D 0.00, G 0.00, 5.9ms\n",
      "Speed: 5.2ms preprocess, 5.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, V 0.00, Y 0.00, D 0.00, K 0.00, 5.9ms\n",
      "Speed: 4.7ms preprocess, 5.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, V 0.00, G 0.00, D 0.00, 6.8ms\n",
      "Speed: 4.7ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, V 0.00, 8.0ms\n",
      "Speed: 4.4ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, V 0.00, K 0.00, 5.8ms\n",
      "Speed: 5.1ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.02, Y 0.00, H 0.00, G 0.00, 6.9ms\n",
      "Speed: 5.2ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.02, N 0.00, H 0.00, G 0.00, 7.6ms\n",
      "Speed: 4.4ms preprocess, 7.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.02, N 0.00, G 0.00, M 0.00, 7.6ms\n",
      "Speed: 5.1ms preprocess, 7.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.97, T 0.02, N 0.00, S 0.00, G 0.00, 7.2ms\n",
      "Speed: 5.0ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.01, G 0.00, H 0.00, S 0.00, 5.8ms\n",
      "Speed: 4.8ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, S 0.00, G 0.00, N 0.00, 5.6ms\n",
      "Speed: 4.4ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, S 0.00, G 0.00, N 0.00, 8.9ms\n",
      "Speed: 5.1ms preprocess, 8.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.02, S 0.00, N 0.00, G 0.00, 9.9ms\n",
      "Speed: 5.0ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.01, S 0.00, N 0.00, G 0.00, 7.0ms\n",
      "Speed: 4.9ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.01, S 0.00, G 0.00, N 0.00, 6.5ms\n",
      "Speed: 4.6ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.99, T 0.01, S 0.00, N 0.00, G 0.00, 7.8ms\n",
      "Speed: 4.3ms preprocess, 7.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.98, T 0.02, S 0.00, N 0.00, G 0.00, 7.2ms\n",
      "Speed: 5.0ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.99, T 0.01, S 0.00, N 0.00, G 0.00, 7.4ms\n",
      "Speed: 4.9ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.99, T 0.01, S 0.00, N 0.00, G 0.00, 8.3ms\n",
      "Speed: 4.7ms preprocess, 8.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 T 0.71, A 0.16, H 0.04, Y 0.03, X 0.02, 8.2ms\n",
      "Speed: 5.0ms preprocess, 8.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, V 0.00, 7.1ms\n",
      "Speed: 4.8ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, G 0.00, V 0.00, 6.2ms\n",
      "Speed: 5.0ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, D 0.00, Y 0.00, V 0.00, G 0.00, 5.8ms\n",
      "Speed: 4.9ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, D 0.00, Y 0.00, V 0.00, G 0.00, 6.9ms\n",
      "Speed: 5.4ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, Y 0.00, D 0.00, V 0.00, K 0.00, 7.3ms\n",
      "Speed: 5.1ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, D 0.00, Y 0.00, V 0.00, G 0.00, 6.4ms\n",
      "Speed: 5.2ms preprocess, 6.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, V 0.00, D 0.00, Y 0.00, K 0.00, 6.0ms\n",
      "Speed: 5.4ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 1.00, D 0.00, V 0.00, Y 0.00, G 0.00, 6.5ms\n",
      "Speed: 4.9ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 L 0.90, Y 0.08, A 0.01, T 0.01, K 0.00, 6.3ms\n",
      "Speed: 4.5ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, Y 0.00, N 0.00, S 0.00, 7.2ms\n",
      "Speed: 4.3ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, Y 0.00, G 0.00, N 0.00, 6.1ms\n",
      "Speed: 4.7ms preprocess, 6.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, N 0.00, M 0.00, Y 0.00, 7.9ms\n",
      "Speed: 4.9ms preprocess, 7.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.99, T 0.00, N 0.00, Y 0.00, M 0.00, 6.0ms\n",
      "Speed: 4.8ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.99, T 0.00, Y 0.00, M 0.00, N 0.00, 7.1ms\n",
      "Speed: 5.0ms preprocess, 7.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 1.00, T 0.00, Y 0.00, M 0.00, N 0.00, 6.2ms\n",
      "Speed: 4.9ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 A 0.94, T 0.02, N 0.01, M 0.01, G 0.01, 8.1ms\n",
      "Speed: 4.9ms preprocess, 8.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.63, Y 0.11, N 0.07, M 0.07, P 0.05, 8.5ms\n",
      "Speed: 4.8ms preprocess, 8.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.29, S 0.10, I 0.07, P 0.07, Y 0.06, 5.8ms\n",
      "Speed: 4.4ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.69, P 0.15, H 0.03, Q 0.02, Y 0.02, 7.4ms\n",
      "Speed: 4.9ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 G 0.72, P 0.10, Y 0.05, H 0.03, Q 0.02, 7.0ms\n",
      "Speed: 4.8ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Captured top class:  [11, 0, 11, 0, 11, 0]\n",
      "Translated text:  [('L', 0.9999525547027588), ('A', 0.999267041683197), ('L', 0.9975687861442566), ('A', 0.9795734882354736), ('L', 0.9991952776908875), ('A', 0.9978876709938049)]\n"
     ]
    }
   ],
   "source": [
    "# This code started as a direct copy from opencv\n",
    "# https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# Info about YOLO import and loading the Yolo Model\n",
    "# https://docs.ultralytics.com/tasks/classify/#train\n",
    "\n",
    "# Added this to import YOLO\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model, this is loading our custom trained weights for our model.\n",
    "model = YOLO(\"best_v2.pt\")\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Stored captured text\n",
    "captured_text = []\n",
    "\n",
    "# Stores captured confidence\n",
    "captured_confidence = []\n",
    "\n",
    "# Set a threshold for the sign to register\n",
    "confidence_requirement = 0.80\n",
    "\n",
    "# Counts the number of consecutive significant signs\n",
    "count = 0\n",
    "\n",
    "# Counts the number of consecutive insignificant signs\n",
    "noise_count = 0\n",
    "\n",
    "# Keeps track of the last sign\n",
    "last = None\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # These two lines are found here https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html\n",
    "    # They reduce the size of the video\n",
    "    \n",
    "    ret = cap.set(cv.CAP_PROP_FRAME_WIDTH,240)\n",
    "    ret = cap.set(cv.CAP_PROP_FRAME_HEIGHT,240)\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    \n",
    "    # If you scroll to the very bottom of this link\n",
    "    # https://docs.ultralytics.com/modes/predict/#thread-safe-inference\n",
    "    # You will find the next 3 lines of code which I took from their and applied to this similar example\n",
    "    \n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = model(frame)\n",
    "    top_class = results[0].probs.top1\n",
    "    top_confidence = results[0].probs.top1conf  # Get confidence of the top-class prediction\n",
    "    \n",
    "    # If the confidence of the sign is above the threshold \n",
    "    if (top_confidence >= confidence_requirement):\n",
    "        \n",
    "        # If the top_class is the last class\n",
    "        # hence it is consecutive increase count by 1.\n",
    "        if (top_class==last):\n",
    "            \n",
    "            count = count+1\n",
    "        \n",
    "        # If the top_class is not the last class\n",
    "        # it is  a new class restart counter \n",
    "        else:\n",
    "    \n",
    "            count=1\n",
    "            \n",
    "        # If there are 3 consecutive significant signs track it\n",
    "        if (count == 3):\n",
    "        \n",
    "            captured_text.append(top_class)\n",
    "            captured_confidence.append(top_confidence)\n",
    "        \n",
    "        # Set last to be the top_class\n",
    "        last = top_class\n",
    "        \n",
    "        # Set the noise counter to 0 since this is not noise\n",
    "        noise_count = 0 \n",
    "    \n",
    "    # If the confidence of the current sign is not enough for the threshold increase noise counter\n",
    "    else:\n",
    "        \n",
    "        noise_count=noise_count+1\n",
    "    \n",
    "    # If there are three consecutive insignificant signs\n",
    "    # Reset count, allowing another consecutive sign to be registerred for instance (A,A)\n",
    "    # Reset the noise counter\n",
    "    if noise_count == 3:\n",
    "        count = 0\n",
    "        noise_count = 0\n",
    "    \n",
    "    # Visualize the results on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Display the annotated frame\n",
    "    cv.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        print(\"Captured top class: \", captured_text)\n",
    "        \n",
    "        # ASCII ref\n",
    "        #https://simple.m.wikipedia.org/wiki/File:ASCII-Table-wide.svg\n",
    "        \n",
    "        # https://stackoverflow.com/questions/3673428/convert-int-to-ascii-and-back-in-python\n",
    "        # Integer to ASCII\n",
    "        \n",
    "        translated_text = []\n",
    "        for i in captured_text:\n",
    "            \n",
    "            if i<26:\n",
    "                translated_text.append(chr(i+65))\n",
    "            elif i==26:\n",
    "                translated_text.append(\"del\")\n",
    "            elif i==27:\n",
    "                translated_text.append(\"nothing\")\n",
    "            elif i==28:\n",
    "                translated_text.append(\"space\")\n",
    "        \n",
    "        for i in range(len(translated_text)):\n",
    "            \n",
    "            translated_text[i] = (translated_text[i], captured_confidence[i].item())\n",
    "        \n",
    "        print(\"Translated text: \", translated_text)\n",
    "        break\n",
    "        \n",
    "        \n",
    " \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
